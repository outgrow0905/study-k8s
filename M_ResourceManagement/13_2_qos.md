## QoS
Pod의 리소스들은 오버커밋 될 수 있다. 
노드에 Pod가 하나만 할당되어 있다고 가정하면 상황에 따라 특정 Pod가 노드의 메모리 대부분을 사용할 수 있고, 혹은 cpu 전체를 사용하게 될 수도 있다.
이런 상황에서 또 다른 Pod가 추가된다면 어떻게 될까? cpu는 압축가능한 자원이지만, 메모리는 그렇지 않다. 
기존 Pod를 제거해야 할까? 만약 제거 대상 후보가 여러 개라면 어떤 우선순위로 제거해야 할까?

kubernetes는 리소스 경합상황에서 Pod의 제거 우선순위를 관리하기 위해 Pod에 QoS를 부여한다.

##### QoS 종류
`BestEffort`: 가장 낮은 우선순위이다. request, limit 모두를 설정하지 않은 Pod에 부여된다. 리소스 제한이 없으므로 원하는 만큼 자원을 사용할 수 있으나, 상황이 여의치 않을 때에는 가장 먼저 제거대상이 된다. 
`Burstable`: `BestEffort`와 `Guaranteed`의 중간이다. 
`Guaranteed`: 가장 높은 우선순위이다. request, limit 모두를 설정하고, request == limit 이어야 한다. 


##### QoS가 같은 Pod끼리는 어떻게 우선순위를 정할까?
모든 프로세스는 OOM 점수를 갖는다. 예를 들어 `Burstable` 클래스의 Pod가 여러개라면, request 대비 메모리 사용비율로 계산한다.  
같은 500M 메모리를 사용중이더라도 request가 높다면 메모리 사용률이 낮을 것이다. 쉽게 이해하자면, 같은 메모리를 사용중이면 request가 낮은 순서대로 종료한다.



## LimitRange
클러스터 관리자는 namespace 단위로 리소스를 제한할 수 있다. LimitRange를 통해 관리자는 아래와 같은 작업을 할 수 있다.

- Pod나 컨테이너 단위로 최대/최소 자원을 강제할 수 있다.
- pvc의 최대/최소 자원을 강제할 수 있다.
- 위의 자원들의 request, limit 비율을 제한할 수 있다.
- 디폴트 request, limit 을 설정하여 request, limit을 설정하지 않은 컨테이너에 자원할당을 자동주입할 수 있다.

~~~yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: example
spec:
  limits:
  - type: Pod
    min:
      cpu: 50m
      memory: 5Mi
    max:
      cpu: 1
      memory: 1Gi
  - type: Container
    defaultRequest:
      cpu: 100m
      memory: 10Mi
    default:
      cpu: 200m
      memory: 100Mi
    min:
      cpu: 50m
      memory: 5Mi
    max:
      cpu: 1
      memory: 1Gi
    maxLimitRequestRatio:
      cpu: 4
      memory: 10
  - type: PersistentVolumeClaim
    min:
      storage: 1Gi
    max:
      storage: 10Gi
~~~



## ResourceQuota
위에서 살펴본 LimitRange 오브젝트는 개별 Pod 단위로 적용된다. LimitRange 기준에만 부합하면 무한대의 Pod를 생성할 수 있는 것이다.  
클러스터 관리자는 ResourceQuota를 통해 namespace 단위로 사용할 수 있는 리소스의 총량을 제한할 수 있다.
또한, ResourceQuota 생성 전에는 LimitRange를 생성해두는 것이 일반적이고 관리자 입장에서도 편리하다.
ResourceQuota가 생성된 이후에는 BestEffort QoS Pod를 생성할 수 없다. request나 limit이 정해지지 않았는데 namespace의 리소스 할당을 관리할 수 없기 때문이다.
예를 들어, ResourceQuota에서 request를 정의헀다면, 이후에 생성되는 모든 Pod에서는 request가 명시되거나 LimitRange를 통해 자동부여해야 한다. 그렇지 않으면 오류가 발생한다. 
생각해보면 당연하다.

추가로, 아래를 보면 `requests.nvidia.com/gpu`와 같이 사용자 정의 리소스도 제한할 수 있다. 다만, 당연히 오버커밋등은 측정이 안될 것이므로, request만 사용할 수 있다.
포멧은 `request.<extended-resource-name>` 이다.

##### cpu, memory
~~~yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
    requests.cpu: "1000m"
    requests.memory: "500Mi"
    limits.cpu: "1500m"
    limits.memory: "1000Mi"
    requests.nvidia.com/gpu: 4
~~~


##### storage
pvc도 설정할 수 있다. 흥미로운 부분은 StorageClass 단위로도 제한이 가능하다는 부분이다.
크기와 개수 모두 설정이 가능하다.
크기의 형식은 `<storage-class-name>.storageclass.storage.k8s.io/requests.storage` 이다.
개수의 형식은 `<storage-class-name>.storageclass.storage.k8s.io/persistentvolumeclaims` 이다.
이를 활용하여 클라우드 비용계획을 세울 수도 있을 것이다.  

1.8 버전부터는 `ephemeral-storage`도 지원한다. 아래 예시에 포함되어있으니 참고하자. 다만,
`ephemeral-storage` 의 계산에는 컨테이너 로그도 포함이 되니, 예상치 못하게 로그가 evict 되지 않도록 신경써야 한다.

~~~yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
    requests.storage: 500Gi
    nks-block-storage.storageclass.storage.k8s.io/requests.storage: 30Gi
    nks-block-storage.storageclass.storage.k8s.io/persistentvolumeclaims: 5
    requests.ephemeral-storage: 30Gi
    limits.ephemeral-storage: 500Gi
~~~

[resource quota](./img/resource-quota.png)

##### count quota
이외의 리소스들은 아래와 같이 개수로 제한이 가능하다.
코어그룹이 아니라면 `count/<resource>.<group>` 의 포멧이고, 코어그룹이라면 `count/<resource` 의 포멧이다. 아래를 참고하자.
사용자 정의 리소스도 물론 제한이 가능하다. `example.com` 그룹의 `widgets` 라는 사용자 정의 리소스를 제한하고 싶다면, 
`count/widgets.example.com` 와 같이 사용하면 된다.

~~~yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: object-counts
spec:
  hard:
    configmaps: "10"
    persistentvolumeclaims: "4"
    pods: "4"
    replicationcontrollers: "20"
    secrets: "10"
    services: "10"
    services.loadbalancers: "2"
    count/widgets.example.com: "2"
~~~

##### quota scopes
Pod의 상태나 QoS에 따라 제한의 범위를 세분화 할수도 있다.
BestEffort, NotBestEffort 등의 설정이 가능하며, BestEffort는 당연히 request, limit 은 설정이 안된다. 개수만 된다.
Terminating, NotTerminating 의 판단은 Pod 혹은 Job의 `.spec.activeDeadlineSeconds` 설정여부로 판단한다. 

~~~yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: object-counts
spec:
  scopes:
  - BestEffort
  - NotTerminating
  hard:
    pods: "4"
~~~

1.16 버전부터는 `PriorityClass` 단위로도 ResourceQuota 설정이 가능하다.
아래 예시를 보면 쉽게 이해가 될 것이다.

~~~yaml
apiVersion: v1
kind: List
items:
- apiVersion: v1
  kind: ResourceQuota
  metadata:
    name: pods-high
  spec:
    hard:
      cpu: "1000"
      memory: 200Gi
      pods: "10"
    scopeSelector:
      matchExpressions:
      - operator : In
        scopeName: PriorityClass
        values: ["high"]
- apiVersion: v1
  kind: ResourceQuota
  metadata:
    name: pods-low
  spec:
    hard:
      cpu: "5"
      memory: 10Gi
      pods: "10"
    scopeSelector:
      matchExpressions:
      - operator : In
        scopeName: PriorityClass
        values: ["low"]
~~~

## Reference
- https://kubernetes.io/docs/concepts/policy/resource-quotas/#viewing-and-setting-quotas
- https://sungjunyoung.github.io/posts/what-is-ephemral-storage/